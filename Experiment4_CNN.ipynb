{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision --quiet\n",
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder, CIFAR10\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print(\"Upload your kaggle.json file\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "print(\"Kaggle configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d salader/dogs-vs-cats\n",
    "!unzip -q dogs-vs-cats.zip -d cats_vs_dogs\n",
    "!unzip -q cats_vs_dogs/train.zip -d cats_vs_dogs/\n",
    "print(\"Dataset downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path('cats_vs_dogs/train')\n",
    "target = Path('cats_vs_dogs/organized')\n",
    "\n",
    "cats_dir = target / 'cats'\n",
    "dogs_dir = target / 'dogs'\n",
    "cats_dir.mkdir(parents=True, exist_ok=True)\n",
    "dogs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "count_cats = 0\n",
    "count_dogs = 0\n",
    "\n",
    "for img in source.glob('*.jpg'):\n",
    "    if 'cat' in img.name:\n",
    "        shutil.copy(img, cats_dir / img.name)\n",
    "        count_cats += 1\n",
    "    elif 'dog' in img.name:\n",
    "        shutil.copy(img, dogs_dir / img.name)\n",
    "        count_dogs += 1\n",
    "\n",
    "print(f\"Organized {count_cats} cats and {count_dogs} dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(dataset_name, batch_size=32):\n",
    "    if dataset_name == 'cats_vs_dogs':\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        dataset = ImageFolder('cats_vs_dogs/organized', transform=transform_train)\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "        val_data.dataset.transform = transform_test\n",
    "        num_classes = 2\n",
    "        \n",
    "    else:\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "        ])\n",
    "        \n",
    "        train_data = CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "        val_data = CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "        num_classes = 10\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, val_loader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(dataset_name):\n",
    "    train_loader, _, _ = get_loaders(dataset_name, 16)\n",
    "    images, labels = next(iter(train_loader))\n",
    "    \n",
    "    if dataset_name == 'cats_vs_dogs':\n",
    "        classes = ['Cat', 'Dog']\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    else:\n",
    "        classes = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "    for i in range(16):\n",
    "        ax = axes[i // 8, i % 8]\n",
    "        img = images[i] * std + mean\n",
    "        img = torch.clamp(img, 0, 1).permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(classes[labels[i]])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples('cats_vs_dogs')\n",
    "show_samples('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation='relu', input_size=128):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        if activation == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif activation == 'tanh':\n",
    "            self.act = nn.Tanh()\n",
    "        else:\n",
    "            self.act = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        feature_size = (input_size // 16) * (input_size // 16) * 256\n",
    "        \n",
    "        self.fc1 = nn.Linear(feature_size, 512)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.act(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(self.act(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.drop1(self.act(self.fc1(x)))\n",
    "        x = self.drop2(self.act(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model, method='xavier'):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            if method == 'xavier':\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif method == 'kaiming':\n",
    "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "            \n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_acc = 0.0\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Loss={train_loss:.4f}, Acc={train_acc:.2f}%, Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%')\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = model.state_dict().copy()\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(dataset_name, epochs=10):\n",
    "    activations = ['relu', 'tanh', 'leaky_relu']\n",
    "    inits = ['xavier', 'kaiming', 'random']\n",
    "    opts = ['sgd', 'adam', 'rmsprop']\n",
    "    \n",
    "    results = []\n",
    "    best_acc = 0\n",
    "    best_config = None\n",
    "    best_model = None\n",
    "    \n",
    "    train_loader, val_loader, num_classes = get_loaders(dataset_name)\n",
    "    input_size = 128 if dataset_name == 'cats_vs_dogs' else 32\n",
    "    \n",
    "    exp_num = 0\n",
    "    total = len(activations) * len(inits) * len(opts)\n",
    "    \n",
    "    for act in activations:\n",
    "        for init in inits:\n",
    "            for opt in opts:\n",
    "                exp_num += 1\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"Experiment {exp_num}/{total}: {dataset_name} | {act} | {init} | {opt}\")\n",
    "                print(f\"{'='*80}\")\n",
    "                \n",
    "                model = CNN(num_classes, act, input_size)\n",
    "                model = init_weights(model, init)\n",
    "                model = model.to(device)\n",
    "                \n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                \n",
    "                if opt == 'sgd':\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "                elif opt == 'adam':\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "                else:\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "                \n",
    "                trained_model, history, acc = train_model(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "                \n",
    "                config = {\n",
    "                    'activation': act,\n",
    "                    'initialization': init,\n",
    "                    'optimizer': opt,\n",
    "                    'best_accuracy': acc,\n",
    "                    'history': history\n",
    "                }\n",
    "                \n",
    "                results.append(config)\n",
    "                \n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_config = config\n",
    "                    best_model = trained_model\n",
    "    \n",
    "    return results, best_config, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Cats vs Dogs experiments...\")\n",
    "cats_results, cats_best, cats_model = run_experiments('cats_vs_dogs', epochs=10)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CATS VS DOGS BEST: {cats_best['activation']} | {cats_best['initialization']} | {cats_best['optimizer']}\")\n",
    "print(f\"Accuracy: {cats_best['best_accuracy']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running CIFAR-10 experiments...\")\n",
    "cifar_results, cifar_best, cifar_model = run_experiments('cifar10', epochs=10)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CIFAR-10 BEST: {cifar_best['activation']} | {cifar_best['initialization']} | {cifar_best['optimizer']}\")\n",
    "print(f\"Accuracy: {cifar_best['best_accuracy']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(results, dataset_name):\n",
    "    acts = list(set([r['activation'] for r in results]))\n",
    "    inits = list(set([r['initialization'] for r in results]))\n",
    "    opts = list(set([r['optimizer'] for r in results]))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    act_accs = {a: np.mean([r['best_accuracy'] for r in results if r['activation'] == a]) for a in acts}\n",
    "    axes[0].bar(act_accs.keys(), act_accs.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    axes[0].set_title('Activation Functions')\n",
    "    axes[0].set_ylabel('Accuracy (%)')\n",
    "    axes[0].set_ylim([0, 100])\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    init_accs = {i: np.mean([r['best_accuracy'] for r in results if r['initialization'] == i]) for i in inits}\n",
    "    axes[1].bar(init_accs.keys(), init_accs.values(), color=['#95E1D3', '#F38181', '#AA96DA'])\n",
    "    axes[1].set_title('Initializations')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_ylim([0, 100])\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    opt_accs = {o: np.mean([r['best_accuracy'] for r in results if r['optimizer'] == o]) for o in opts}\n",
    "    axes[2].bar(opt_accs.keys(), opt_accs.values(), color=['#FECA57', '#48DBFB', '#FF9FF3'])\n",
    "    axes[2].set_title('Optimizers')\n",
    "    axes[2].set_ylabel('Accuracy (%)')\n",
    "    axes[2].set_ylim([0, 100])\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'{dataset_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(cats_results, 'Cats vs Dogs')\n",
    "plot_comparison(cifar_results, 'CIFAR-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train', linewidth=2, color='#FF6B6B')\n",
    "    axes[0].plot(history['val_loss'], label='Val', linewidth=2, color='#4ECDC4')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history['train_acc'], label='Train', linewidth=2, color='#FF6B6B')\n",
    "    axes[1].plot(history['val_acc'], label='Val', linewidth=2, color='#4ECDC4')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(cats_best['history'], 'Cats vs Dogs - Best Model')\n",
    "plot_history(cifar_best['history'], 'CIFAR-10 - Best Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(dataset_name, epochs=10):\n",
    "    train_loader, val_loader, num_classes = get_loaders(dataset_name)\n",
    "    \n",
    "    model = resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model, history, acc = train_model(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "    return model, history, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training ResNet-18 on Cats vs Dogs...\")\n",
    "resnet_cats, resnet_cats_hist, resnet_cats_acc = train_resnet('cats_vs_dogs', 10)\n",
    "print(f\"ResNet-18 Accuracy: {resnet_cats_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training ResNet-18 on CIFAR-10...\")\n",
    "resnet_cifar, resnet_cifar_hist, resnet_cifar_acc = train_resnet('cifar10', 10)\n",
    "print(f\"ResNet-18 Accuracy: {resnet_cifar_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(custom_acc, resnet_acc, dataset_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    models = ['Custom CNN', 'ResNet-18']\n",
    "    accs = [custom_acc, resnet_acc]\n",
    "    \n",
    "    bars = ax.bar(models, accs, color=['#FF6B6B', '#4ECDC4'], alpha=0.8, width=0.5)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title(f'{dataset_name}')\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2f}%',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Custom CNN: {custom_acc:.2f}%\")\n",
    "    print(f\"ResNet-18: {resnet_acc:.2f}%\")\n",
    "    print(f\"Difference: {abs(resnet_acc - custom_acc):.2f}%\")\n",
    "\n",
    "compare_models(cats_best['best_accuracy'], resnet_cats_acc, 'Cats vs Dogs')\n",
    "compare_models(cifar_best['best_accuracy'], resnet_cifar_acc, 'CIFAR-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "torch.save({'model_state_dict': cats_model.state_dict(), 'config': cats_best, 'accuracy': cats_best['best_accuracy']}, 'saved_models/cats_dogs_best_cnn.pth')\n",
    "torch.save({'model_state_dict': cifar_model.state_dict(), 'config': cifar_best, 'accuracy': cifar_best['best_accuracy']}, 'saved_models/cifar10_best_cnn.pth')\n",
    "torch.save({'model_state_dict': resnet_cats.state_dict(), 'accuracy': resnet_cats_acc}, 'saved_models/cats_dogs_resnet18.pth')\n",
    "torch.save({'model_state_dict': resnet_cifar.state_dict(), 'accuracy': resnet_cifar_acc}, 'saved_models/cifar10_resnet18.pth')\n",
    "\n",
    "print(\"Models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = {\n",
    "    'cats_vs_dogs': {\n",
    "        'best_config': {'activation': cats_best['activation'], 'initialization': cats_best['initialization'], 'optimizer': cats_best['optimizer'], 'accuracy': float(cats_best['best_accuracy'])},\n",
    "        'resnet18_accuracy': float(resnet_cats_acc),\n",
    "        'all_experiments': [{'activation': r['activation'], 'initialization': r['initialization'], 'optimizer': r['optimizer'], 'accuracy': float(r['best_accuracy'])} for r in cats_results]\n",
    "    },\n",
    "    'cifar10': {\n",
    "        'best_config': {'activation': cifar_best['activation'], 'initialization': cifar_best['initialization'], 'optimizer': cifar_best['optimizer'], 'accuracy': float(cifar_best['best_accuracy'])},\n",
    "        'resnet18_accuracy': float(resnet_cifar_acc),\n",
    "        'all_experiments': [{'activation': r['activation'], 'initialization': r['initialization'], 'optimizer': r['optimizer'], 'accuracy': float(r['best_accuracy'])} for r in cifar_results]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('saved_models/experiment_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4)\n",
    "\n",
    "print(\"Results saved to JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\" \" * 40 + \"FINAL REPORT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\nCATS VS DOGS:\")\n",
    "print(f\"  Best: {cats_best['activation']} | {cats_best['initialization']} | {cats_best['optimizer']}\")\n",
    "print(f\"  Custom CNN: {cats_best['best_accuracy']:.2f}%\")\n",
    "print(f\"  ResNet-18: {resnet_cats_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nCIFAR-10:\")\n",
    "print(f\"  Best: {cifar_best['activation']} | {cifar_best['initialization']} | {cifar_best['optimizer']}\")\n",
    "print(f\"  Custom CNN: {cifar_best['best_accuracy']:.2f}%\")\n",
    "print(f\"  ResNet-18: {resnet_cifar_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r saved_models.zip saved_models/\n",
    "from google.colab import files\n",
    "files.download('saved_models.zip')\n",
    "print(\"Downloaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
