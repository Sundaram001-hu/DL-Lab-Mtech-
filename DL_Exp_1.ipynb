{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exp. Tensor Operations with PyTorch and NumPy\n",
        "\n",
        "- Creating 1D, 2D, and 3D tensors\n",
        "- Basic element-wise operations\n",
        "- Dot product and matrix multiplication\n",
        "- Indexing and slicing\n",
        "- Shape manipulation (view, reshape, unsqueeze, squeeze)\n",
        "- Broadcasting\n",
        "- In-place vs out-of-place operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating 1D, 2D, and 3D Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1D Tensors\n",
        "print(\"1.1 1D Tensors:\")\n",
        "torch_1d = torch.tensor([1, 2, 3, 4, 5])\n",
        "numpy_1d = np.array([1, 2, 3, 4, 5])\n",
        "print(f\"PyTorch 1D: {torch_1d}, shape: {torch_1d.shape}\")\n",
        "print(f\"NumPy 1D: {numpy_1d}, shape: {numpy_1d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D Tensors (Matrices)\n",
        "print(\"1.2 2D Tensors (Matrices):\")\n",
        "torch_2d = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "numpy_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(f\"PyTorch 2D:\\n{torch_2d}\\nshape: {torch_2d.shape}\")\n",
        "print(f\"\\nNumPy 2D:\\n{numpy_2d}\\nshape: {numpy_2d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3D Tensors\n",
        "print(\"1.3 3D Tensors:\")\n",
        "torch_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
        "numpy_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
        "print(f\"PyTorch 3D:\\n{torch_3d}\\nshape: {torch_3d.shape}\")\n",
        "print(f\"\\nNumPy 3D:\\n{numpy_3d}\\nshape: {numpy_3d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating tensors with specific values\n",
        "print(\"1.4 Special Tensor Creation:\")\n",
        "print(f\"Zeros (2x3):\\n{torch.zeros(2, 3)}\")\n",
        "print(f\"\\nOnes (2x3):\\n{torch.ones(2, 3)}\")\n",
        "print(f\"\\nRandom (2x3):\\n{torch.randn(2, 3)}\")\n",
        "print(f\"\\nArange (0-9): {torch.arange(0, 10)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Element-wise Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "b = torch.tensor([5, 6, 7, 8], dtype=torch.float32)\n",
        "print(f\"Tensor a: {a}\")\n",
        "print(f\"Tensor b: {b}\")\n",
        "print(f\"\\n2.1 Addition (a + b): {a + b}\")\n",
        "print(f\"2.2 Subtraction (a - b): {a - b}\")\n",
        "print(f\"2.3 Multiplication (a * b): {a * b}\")\n",
        "print(f\"2.4 Division (b / a): {b / a}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy equivalent\n",
        "a_np = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "b_np = np.array([5, 6, 7, 8], dtype=np.float32)\n",
        "print(f\"NumPy Addition: {a_np + b_np}\")\n",
        "print(f\"NumPy Subtraction: {a_np - b_np}\")\n",
        "print(f\"NumPy Multiplication: {a_np * b_np}\")\n",
        "print(f\"NumPy Division: {b_np / a_np}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D element-wise operations\n",
        "print(\"2.5 2D Element-wise Operations:\")\n",
        "matrix_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "matrix_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "print(f\"Matrix A:\\n{matrix_a}\")\n",
        "print(f\"\\nMatrix B:\\n{matrix_b}\")\n",
        "print(f\"\\nA + B:\\n{matrix_a + matrix_b}\")\n",
        "print(f\"\\nA * B (element-wise):\\n{matrix_a * matrix_b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dot Product and Matrix Multiplication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dot product for 1D tensors\n",
        "vec1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "vec2 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
        "print(\"3.1 Dot Product (1D vectors):\")\n",
        "print(f\"Vector 1: {vec1}\")\n",
        "print(f\"Vector 2: {vec2}\")\n",
        "print(f\"Dot product (torch.dot): {torch.dot(vec1, vec2)}\")\n",
        "print(f\"Alternative (sum of element-wise): {(vec1 * vec2).sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrix multiplication\n",
        "print(\"3.2 Matrix Multiplication:\")\n",
        "mat_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "mat_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "print(f\"Matrix A (2x2):\\n{mat_a}\")\n",
        "print(f\"\\nMatrix B (2x2):\\n{mat_b}\")\n",
        "print(f\"\\nMatrix Multiplication (A @ B):\\n{mat_a @ mat_b}\")\n",
        "print(f\"\\nAlternative (torch.mm):\\n{torch.mm(mat_a, mat_b)}\")\n",
        "print(f\"\\nAlternative (torch.matmul):\\n{torch.matmul(mat_a, mat_b)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy equivalent\n",
        "mat_a_np = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
        "mat_b_np = np.array([[5, 6], [7, 8]], dtype=np.float32)\n",
        "print(\"NumPy Matrix Multiplication:\")\n",
        "print(f\"{np.matmul(mat_a_np, mat_b_np)}\")\n",
        "print(f\"\\nNumPy @ operator:\\n{mat_a_np @ mat_b_np}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Batch matrix multiplication\n",
        "print(\"3.3 Batch Matrix Multiplication:\")\n",
        "batch_a = torch.randn(3, 4, 5)  \n",
        "batch_b = torch.randn(3, 5, 6)  \n",
        "batch_result = torch.bmm(batch_a, batch_b)\n",
        "print(f\"Batch A shape: {batch_a.shape}\")\n",
        "print(f\"Batch B shape: {batch_b.shape}\")\n",
        "print(f\"Result shape: {batch_result.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Indexing and Slicing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic indexing\n",
        "tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print(\"4.1 Basic Indexing and Slicing:\")\n",
        "print(f\"Original tensor (3x4):\\n{tensor}\")\n",
        "print(f\"\\nElement at [0, 1]: {tensor[0, 1]}\")\n",
        "print(f\"First row: {tensor[0, :]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Submatrix [0:2, 1:3]:\\n{tensor[0:2, 1:3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boolean masking\n",
        "print(\"4.2 Boolean Masking:\")\n",
        "mask = tensor > 5\n",
        "print(f\"Original tensor:\\n{tensor}\")\n",
        "print(f\"\\nBoolean mask (values > 5):\\n{mask}\")\n",
        "print(f\"Values where mask is True: {tensor[mask]}\")\n",
        "print(f\"Values > 5: {tensor[tensor > 5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced indexing\n",
        "print(\"4.3 Advanced Indexing:\")\n",
        "print(f\"Select rows [0, 2]:\\n{tensor[[0, 2], :]}\")\n",
        "print(f\"Select columns [1, 3]:\\n{tensor[:, [1, 3]]}\")\n",
        "print(f\"Select specific elements [0,0] and [2,2]: {tensor[[0, 2], [0, 2]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extracting subtensors\n",
        "print(\"4.4 Extracting Subtensors:\")\n",
        "print(f\"First 2 rows:\\n{tensor[:2, :]}\")\n",
        "print(f\"Last 2 columns:\\n{tensor[:, -2:]}\")\n",
        "print(f\"Center 2x2 submatrix:\\n{tensor[1:3, 1:3]}\")\n",
        "tensor_np = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print(f\"\\nNumPy Boolean Masking (values > 5): {tensor_np[tensor_np > 5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Shape Manipulation: View, Reshape, Unsqueeze, Squeeze\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original tensor\n",
        "original = torch.arange(12)\n",
        "print(f\"5.1 Original tensor: {original}, shape: {original.shape}\")\n",
        "reshaped_view = original.view(3, 4)\n",
        "print(f\"\\n.view(3, 4):\\n{reshaped_view}\\nshape: {reshaped_view.shape}\")\n",
        "reshaped_view_1d = original.view(2, 6)\n",
        "print(f\"\\n.view(2, 6):\\n{reshaped_view_1d}\\nshape: {reshaped_view_1d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .reshape() - similar to view but can handle non-contiguous tensors\n",
        "reshaped = original.reshape(4, 3)\n",
        "print(f\"5.2 .reshape(4, 3):\\n{reshaped}\\nshape: {reshaped.shape}\")\n",
        "reshaped_3d = original.reshape(2, 2, 3)\n",
        "print(f\"\\n.reshape(2, 2, 3):\\n{reshaped_3d}\\nshape: {reshaped_3d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .unsqueeze() - adds dimension of size 1 at specified position\n",
        "unsqueezed_0 = original.unsqueeze(0)\n",
        "print(f\"5.3 .unsqueeze(0) (add dim at start): {unsqueezed_0}, shape: {unsqueezed_0.shape}\")\n",
        "unsqueezed_1 = original.unsqueeze(1)\n",
        "print(f\".unsqueeze(1) (add dim at position 1):\\n{unsqueezed_1}\\nshape: {unsqueezed_1.shape}\")\n",
        "unsqueezed_neg = original.unsqueeze(-1)\n",
        "print(f\".unsqueeze(-1) (add dim at end):\\n{unsqueezed_neg}\\nshape: {unsqueezed_neg.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# .squeeze() - removes dimensions of size 1\n",
        "tensor_with_ones = torch.randn(1, 3, 1, 4)\n",
        "print(f\"5.4 Original tensor with ones: shape {tensor_with_ones.shape}\")\n",
        "squeezed_all = tensor_with_ones.squeeze()\n",
        "print(f\".squeeze() (remove all dims of size 1): shape {squeezed_all.shape}\")\n",
        "squeezed_specific = tensor_with_ones.squeeze(0)\n",
        "print(f\".squeeze(0) (remove dim at position 0): shape {squeezed_specific.shape}\")\n",
        "squeezed_specific2 = tensor_with_ones.squeeze(2)\n",
        "print(f\".squeeze(2) (remove dim at position 2): shape {squeezed_specific2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy .reshape() comparison\n",
        "print(\"5.5 NumPy .reshape() Comparison:\")\n",
        "original_np = np.arange(12)\n",
        "print(f\"Original NumPy array: {original_np}, shape: {original_np.shape}\")\n",
        "reshaped_np = original_np.reshape(3, 4)\n",
        "print(f\"NumPy .reshape(3, 4):\\n{reshaped_np}\\nshape: {reshaped_np.shape}\")\n",
        "reshaped_np_3d = original_np.reshape(2, 2, 3)\n",
        "print(f\"NumPy .reshape(2, 2, 3):\\n{reshaped_np_3d}\\nshape: {reshaped_np_3d.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy expand_dims and squeeze\n",
        "print(\"NumPy .expand_dims() (like unsqueeze):\")\n",
        "expanded = np.expand_dims(original_np, axis=0)\n",
        "print(f\"np.expand_dims(arr, axis=0): shape {expanded.shape}\")\n",
        "expanded_1 = np.expand_dims(original_np, axis=1)\n",
        "print(f\"np.expand_dims(arr, axis=1): shape {expanded_1.shape}\")\n",
        "print(f\"\\nNumPy .squeeze():\")\n",
        "ones_np = np.random.randn(1, 3, 1, 4)\n",
        "print(f\"Original shape: {ones_np.shape}\")\n",
        "squeezed_np = np.squeeze(ones_np)\n",
        "print(f\"np.squeeze(): shape {squeezed_np.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Broadcasting - Operations with Different Shapes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Broadcasting in PyTorch\n",
        "print(\"6.1 PyTorch Broadcasting:\")\n",
        "\n",
        "# Eg.1: Adding scalar to tensor\n",
        "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
        "scalar = 10.0\n",
        "print(f\"Tensor (2x3):\\n{tensor_2d}\")\n",
        "print(f\"Scalar: {scalar}\")\n",
        "print(f\"Tensor + Scalar:\\n{tensor_2d + scalar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eg.2: Adding 1D to 2D\n",
        "vector = torch.tensor([10, 20, 30], dtype=torch.float32)\n",
        "print(f\"Tensor (2x3):\\n{tensor_2d}\")\n",
        "print(f\"Vector (1D): {vector}\")\n",
        "print(f\"Tensor + Vector (broadcasting):\\n{tensor_2d + vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eg.3: Adding column vector to matrix\n",
        "col_vector = torch.tensor([[10], [20]], dtype=torch.float32)\n",
        "print(f\"Tensor (2x3):\\n{tensor_2d}\")\n",
        "print(f\"Column Vector (2x1):\\n{col_vector}\")\n",
        "print(f\"Tensor + Column Vector:\\n{tensor_2d + col_vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eg.4: More complex broadcasting\n",
        "tensor_a = torch.randn(5, 1, 4, 1)\n",
        "tensor_b = torch.randn(3, 1, 1)\n",
        "print(f\"Tensor A shape: {tensor_a.shape}\")\n",
        "print(f\"Tensor B shape: {tensor_b.shape}\")\n",
        "result = tensor_a + tensor_b\n",
        "print(f\"Broadcasted result shape: {result.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy broadcasting\n",
        "print(\"6.2 NumPy Broadcasting:\")\n",
        "tensor_2d_np = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
        "vector_np = np.array([10, 20, 30], dtype=np.float32)\n",
        "print(f\"NumPy Tensor (2x3):\\n{tensor_2d_np}\")\n",
        "print(f\"NumPy Vector: {vector_np}\")\n",
        "print(f\"NumPy Broadcasting result:\\n{tensor_2d_np + vector_np}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. In-Place vs Out-of-Place Operations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Out-of-place operations \n",
        "print(\"7.1 Out-of-Place Operations:\")\n",
        "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "print(f\"Original tensor x: {x}, id: {id(x)}\")\n",
        "y = x + 1 \n",
        "print(f\"After y = x + 1:\")\n",
        "print(f\"x: {x}, id: {id(x)}\")\n",
        "print(f\"y: {y}, id: {id(y)}\")\n",
        "print(f\"Are x and y the same object? {x is y}\")\n",
        "z = x * 2  \n",
        "print(f\"\\nAfter z = x * 2:\")\n",
        "print(f\"x: {x}, z: {z}\")\n",
        "print(f\"Are x and z the same object? {x is z}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In-place operations \n",
        "print(\"7.2 In-Place Operations:\")\n",
        "x_inplace = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "print(f\"Original tensor x_inplace: {x_inplace}, id: {id(x_inplace)}\")\n",
        "x_inplace.add_(1)  \n",
        "print(f\"After x_inplace.add_(1): {x_inplace}, id: {id(x_inplace)}\")\n",
        "x_inplace.mul_(2) \n",
        "print(f\"After x_inplace.mul_(2): {x_inplace}, id: {id(x_inplace)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common in-place operations\n",
        "print(\"7.3 Common In-Place Operations:\")\n",
        "t = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "print(f\"Original: {t}\")\n",
        "t += 5  \n",
        "print(f\"After t += 5: {t}\")\n",
        "t *= 2 \n",
        "print(f\"After t *= 2: {t}\")\n",
        "t1 = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "print(f\"\\nOriginal matrix:\\n{t1}\")\n",
        "t1.transpose_(0, 1)  \n",
        "print(f\"After transpose_():\\n{t1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison: Memory efficiency\n",
        "print(\"7.4 Memory Efficiency Comparison:\")\n",
        "large_tensor = torch.randn(1000, 1000)\n",
        "print(f\"Large tensor shape: {large_tensor.shape}\")\n",
        "result_out = large_tensor + 1  \n",
        "print(f\"Out-of-place: result and original are different objects\")\n",
        "\n",
        "# In-place (memory efficient)\n",
        "large_tensor.add_(1)  \n",
        "print(f\"In-place: modifies existing tensor (no extra memory)\")\n",
        "print(\"\\nNote: In-place operations modify the original tensor and cannot be\")\n",
        "print(\"      reversed. Use with caution, especially with autograd enabled!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NumPy in-place operations\n",
        "print(\"7.5 NumPy In-Place Operations:\")\n",
        "arr = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "print(f\"Original NumPy array: {arr}, id: {id(arr)}\")\n",
        "arr += 10  \n",
        "print(f\"After arr += 10: {arr}, id: {id(arr)}\")\n",
        "arr *= 2  \n",
        "print(f\"After arr *= 2: {arr}, id: {id(arr)}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
